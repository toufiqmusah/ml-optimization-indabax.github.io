<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Advanced Optimization in Machine Learning</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Inter', sans-serif;
      background: #f9f9f9;
      color: #333;
      line-height: 1.6;
      max-width: 900px;
      margin: auto;
      padding: 2rem;
    }
    h1 {
      font-size: 2.2rem;
      margin-bottom: 0.2rem;
    }
    h2 {
      color: #222;
      margin-top: 2rem;
    }
    h3 {
      color: #333;
      margin-top: 1.5rem;
    }
    a {
      color: #0066cc;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .badge {
      margin-top: 0.5rem;
    }
    code, pre {
      background: #eee;
      padding: 0.2rem 0.4rem;
      border-radius: 4px;
      font-size: 0.95rem;
    }
    blockquote {
      border-left: 4px solid #ccc;
      margin: 1.5rem 0;
      padding-left: 1rem;
      font-style: italic;
    }
    hr {
      margin: 2rem 0;
    }
    .info-section {
      margin-top: 2rem;
      background: #fff;
      padding: 1.5rem;
      border-left: 4px solid #555;
      box-shadow: 0 0 10px rgba(0,0,0,0.05);
    }
    .info-section h4 {
      margin-bottom: 0.2rem;
      font-size: 1.2rem;
    }
    .info-section p {
      margin: 0.3rem 0;
    }
  </style>
</head>
<body>
  <div class="info-section">
    <h2>üìò Ghana Data Science Summit ‚Äì IndabaX Ghana 2025</h2>

    <h4>üë®‚Äçüè´ Facilitators: Ishaya, Jeremiah Ayock & Toufiq Musah</h4>
    <hr>
    <p>üè´ Institution: AIMS-RIC and ACITY</p>
    <p><strong>Jeremiah Ayock Ishaya</strong> ‚Äì Lecturer and Researcher in Machine Learning</p>
    <p>‚úâÔ∏è <a href="mailto:ayockishaya1029@gmail.com">ayockishaya1029@gmail.com</a></p>
    <p>üîó <a href="https://www.linkedin.com/in/jeremiah-ayock-ishaya-a49a9999/" target="_blank">LinkedIn: jeremiah</a></p>

    <hr>
    <p>üè´ Institution: Kumasi Centre for Collaborative Research in Tropical Medicine (KCCR)</p>
    <p><strong>Toufiq Musah</strong> ‚Äì Research & Engineering at KCCR</p>
    <p>üëÅÔ∏è <a href="https://toufiqmusah.github.io/" target="_blank">toufiqmusah.github.io</a></p>
    <p>‚úâÔ∏è <a href="mailto:toufiqmusah32@gmail.com">toufiqmusah32@gmail.com</a></p>
    <p>üîó <a href="https://www.linkedin.com/in/toufiqmusah/" target="_blank">LinkedIn: toufiq</a></p>
  </div>

  <h1>Advanced Optimization in Machine Learning</h1>
  <p>
    This tutorial series balances theoretical foundations (~30 minutes) with practical implementations. It includes algorithm explanations, hands-on implementations, comparative experiments, and deployment-aware optimization techniques.
  </p>
  <blockquote>
    ‚öôÔ∏è <em>The tutorial is divided into four parts: foundational theory, core method implementation, comparative experiments, and deployment-oriented optimization.</em>
  </blockquote>

  <h2>1. Part 1 - Optimization Techniques in Machine Learning</h2>
  <p><strong>Focus:</strong> Theoretical overview of classical and modern optimization algorithms.</p>
  <ul>
    <li>Why Optimization Matters in ML</li>
    <li>Gradient-Based Optimization</li>
    <li>Second-Order & Advanced Methods</li>
    <li>Hyperparameter Optimization</li>
  </ul>

  <h2>2. Part 2 - Practical Implementation of Optimization Methods</h2>
  <p><strong>Focus:</strong> From-scratch implementation using NumPy.</p>
  <ul>
    <li>Simple NumPy Neural Network</li>
    <li>Activation Functions: ReLU, Tanh</li>
    <li>Gradient Descent Variants</li>
    <li>Linear Quantization</li>
    <li>Single-line TensorFlow Comparison</li>
  </ul>
  <div class="badge">
    <a href="https://colab.research.google.com/drive/1pgsMo4c0Iax79YITcj1xiocbarkBhRLu?usp=sharing" target="_blank" rel="noopener noreferrer">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
    </a>
  </div>

  <h2>3. Part 3 - Advanced Optimization ML</h2>
  <p><strong>Focus:</strong> Comparative optimizer performance, learning rate scheduling, and regularization.</p>
  <ul>
    <li>Optimizer dynamics (SGD, Adam, RMSProp)</li>
    <li>Performance comparison using Keras</li>
    <li>Learning Rate Scheduling: ExponentialDecay, CosineDecay, OneCycleLR</li>
    <li>Dropout & L2 Regularization</li>
    <li>Hyperparameter tuning with Optuna</li>
    <li>Guided optimization challenge</li>
  </ul>
  <div class="badge">
    <a href="https://colab.research.google.com/drive/1Hq3vD2aYJdUkIYZsUGxagkVT2EqXBY95?usp=sharing" target="_blank" rel="noopener noreferrer">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
    </a>
  </div>

  <h2>4. Part 4 - Neural Architecture Search & Deployment Optimization</h2>
  <p><strong>Focus:</strong> Optimization beyond training‚Äîdesign, compression, and deployment.</p>
  <ul>
    <li>Introduction & Dataset Overview</li>
    <li>Neural Architecture Search (NAS)</li>
    <li>Post-Training Quantization</li>
    <li>Quantization-Aware Training (QAT)</li>
  </ul>
  <div class="badge">
    <a href="https://colab.research.google.com/drive/10VieqNeG6X8nnb-s2BjWEgYC9A4CMkHO?usp=sharing" target="_blank" rel="noopener noreferrer">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab">
    </a>
  </div>

  <h2>5. requirements.txt</h2>
  <p>Install required packages:</p>
  <pre><code>pip install -r requirements.txt</code></pre>
</body>
</html>
